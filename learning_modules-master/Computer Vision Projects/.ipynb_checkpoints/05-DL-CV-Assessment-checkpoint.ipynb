{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
